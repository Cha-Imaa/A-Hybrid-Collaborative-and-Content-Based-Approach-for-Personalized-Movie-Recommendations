{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook2: User-based Collaborative Filtering Movie Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the environment path for the dataset\n",
    "os.environ['BASE_PATH'] = '/l/users/chaimaa.abi/BigData2/BigData/Dataset/ml-25m/ml-25m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch data correctly handling headers\n",
    "def fetch_data(file_name, nrows=None):\n",
    "    base_path = os.getenv('BASE_PATH')  # Get the base path from the environment variables\n",
    "    full_data_path = os.path.join(base_path, file_name)  # Create the full path by joining the base path with the file name\n",
    "    return pd.read_csv(full_data_path, nrows=nrows)  # Read the CSV file located at the full path, optionally reading only a certain number of rows specified by 'nrows'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function computes similarities between movies based on user rating patterns. The similarities can be used by a recommendation system to suggest new movies to users.\n",
    "\n",
    "It takes a matrix of user ratings for movies and computes one of three similarity measures between movie pairs:\n",
    "\n",
    "1. Pearson Correlation: Linear correlation of rating patterns.\n",
    "2. Cosine Similarity: Angle between rating vectors. \n",
    "3. Jaccard Similarity: Overlap of users who rated each movie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute different similarities\n",
    "def compute_similarities(matrix, method='pearson'):\n",
    "    # Check if the matrix is empty or entirely NaN\n",
    "    if matrix.empty or matrix.isna().all().all():\n",
    "        print(\"Warning: The matrix is empty or entirely NaN.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame as a safe fallback\n",
    "\n",
    "    # Pearson correlation\n",
    "    if method == 'pearson':\n",
    "        return matrix.T.corr()\n",
    "    # Cosine similarity\n",
    "    elif method == 'cosine':\n",
    "        # Normalize the matrix by subtracting the mean of each row\n",
    "        normalized_matrix = matrix.sub(matrix.mean(axis=1), axis=0).fillna(0)\n",
    "        if normalized_matrix.empty:\n",
    "            print(\"Warning: Normalized matrix is empty.\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if the normalized matrix is empty\n",
    "        # Compute cosine similarity between rows\n",
    "        return pd.DataFrame(cosine_similarity(normalized_matrix), index=matrix.index, columns=matrix.index)\n",
    "    # Jaccard similarity\n",
    "    elif method == 'jaccard':\n",
    "        # Convert the matrix to binary (1 for non-NaN values, 0 for NaN values)\n",
    "        binary_matrix = matrix.notna().astype(int)\n",
    "        # Compute intersection of binary matrix\n",
    "        intersection = np.dot(binary_matrix, binary_matrix.T)\n",
    "        # Compute sum of rows\n",
    "        row_sums = binary_matrix.sum(axis=1).values\n",
    "        # Compute union of binary matrix\n",
    "        union = row_sums.reshape(-1, 1) + row_sums - intersection\n",
    "        # Compute Jaccard similarity between rows\n",
    "        jaccard = np.where(union == 0, 0, intersection / union)\n",
    "        return pd.DataFrame(jaccard, index=matrix.index, columns=matrix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(data, user_matrix, norm_matrix, sim_matrix):\n",
    "    estimates = []\n",
    "    for _, row in data.iterrows():\n",
    "        pred_rating = predict_rating(row['userId'], row['movieId'], user_matrix, norm_matrix, sim_matrix)\n",
    "        if not np.isnan(pred_rating):  # Ensure the prediction is valid\n",
    "            estimates.append((pred_rating, row['rating']))\n",
    "\n",
    "    # Calculate RMSE only on estimated ratings\n",
    "    if estimates:\n",
    "        predicted, actual = zip(*estimates)  # This separates predicted and actual ratings into separate tuples\n",
    "        return np.sqrt(mean_squared_error(actual, predicted))\n",
    "    else:\n",
    "        return None  # or a sensible default/error message\n",
    "\n",
    "# Revising the prediction function to handle edge cases better:\n",
    "def predict_rating(user, item, user_matrix, norm_matrix, sim_matrix):\n",
    "    if item not in user_matrix.columns:\n",
    "        return np.nan  # Use NaN for items that have no ratings, so they don't affect RMSE\n",
    "\n",
    "    relevant_users = norm_matrix[item].dropna()\n",
    "    weights = sim_matrix.loc[user].reindex(relevant_users.index).dropna()\n",
    "\n",
    "    if weights.empty:\n",
    "        return np.nan  # Return NaN if no similar users to avoid affecting RMSE\n",
    "\n",
    "    weighted_sum = (relevant_users * weights).sum()\n",
    "    scale = abs(weights).sum()\n",
    "    base = user_matrix.loc[user].mean()\n",
    "\n",
    "    return base + (weighted_sum / scale if scale else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations including movie names\n",
    "def generate_recommendations(user_id, user_item_matrix, similarity_matrix, movies_df, num_recommendations=10):\n",
    "    # Get the list of unrated items for the user\n",
    "    unrated_items = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id].isna()].index\n",
    "    # Create a dictionary to store predicted ratings for unrated items\n",
    "    predictions = {item: predict_rating(user_id, item, user_item_matrix, user_item_matrix.subtract(user_item_matrix.mean(axis=1), axis=0).fillna(0), similarity_matrix) for item in unrated_items}\n",
    "    # Sort the predictions in descending order of predicted rating\n",
    "    recommended_items = sorted(predictions.items(), key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
    "    # Get the movie details for the recommended items\n",
    "    recommended_movies = movies_df[movies_df['movieId'].isin([item[0] for item in recommended_items])]\n",
    "    # Add the predicted ratings to the recommended movies DataFrame\n",
    "    recommended_movies['predicted_rating'] = [item[1] for item in recommended_items if item[0] in recommended_movies['movieId'].values]\n",
    "    # Return the recommended movies DataFrame with movie titles and predicted ratings\n",
    "    return recommended_movies[['title', 'predicted_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_user(user_matrix, movies_df, user_id=99999):\n",
    "    \"\"\" Simulate a new user with specific ratings. \"\"\"\n",
    "\n",
    "    # Example movies and ratings\n",
    "    simulated_ratings = {\n",
    "        1: 5.0,  # Toy Story\n",
    "        6377: 4.5,  # Finding Nemo\n",
    "        6991: 5.0  # Tarzan\n",
    "    }\n",
    "\n",
    "    # Create a new row for the user\n",
    "    new_user_row = pd.Series(\n",
    "        data=[simulated_ratings.get(movie_id, np.nan) for movie_id in user_matrix.columns],\n",
    "        index=user_matrix.columns\n",
    "    )\n",
    "\n",
    "    # Append the row to the user matrix\n",
    "    user_matrix.loc[user_id] = new_user_row\n",
    "\n",
    "    return user_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Fetch data from CSV files\n",
    "    ratings = fetch_data('ratings.csv')\n",
    "    movies = fetch_data('movies.csv')\n",
    "\n",
    "    # Create a user-item matrix and normalize it\n",
    "    user_matrix = ratings.pivot_table(values='rating', index='userId', columns='movieId', aggfunc='mean').fillna(0)\n",
    "    norm_matrix = user_matrix.subtract(user_matrix.mean(axis=1), axis=0)\n",
    "    print(\"User Matrix and Norm Matrix Created.\")\n",
    "\n",
    "    # Compute similarity matrices\n",
    "    pearson_sim = compute_similarities(user_matrix, 'pearson')\n",
    "    cosine_sim = compute_similarities(user_matrix, 'cosine')\n",
    "    jaccard_sim = compute_similarities(user_matrix, 'jaccard')\n",
    "    print(\"Similarity Matrices Computed.\")\n",
    "\n",
    "    # Compute RMSE for different similarity measures\n",
    "    rmse_pearson = compute_rmse(ratings, user_matrix, norm_matrix, pearson_sim)\n",
    "    rmse_cosine = compute_rmse(ratings, user_matrix, norm_matrix, cosine_sim)\n",
    "    rmse_jaccard = compute_rmse(ratings, user_matrix, norm_matrix, jaccard_sim)\n",
    "    print(f\"RMSE for Pearson Correlation: {rmse_pearson}\")\n",
    "    print(f\"RMSE for Cosine Similarity: {rmse_cosine}\")\n",
    "    print(f\"RMSE for Jaccard Similarity: {rmse_jaccard}\")\n",
    "\n",
    "    # Simulate a new user\n",
    "    user_id = 99999  # A unique identifier for the simulated user\n",
    "    user_matrix = simulate_user(user_matrix, movies, user_id)\n",
    "\n",
    "    # Recompute the normalized matrix and similarities\n",
    "    norm_matrix = user_matrix.subtract(user_matrix.mean(axis=1), axis=0)\n",
    "    pearson_sim = compute_similarities(user_matrix, 'pearson')\n",
    "\n",
    "    # Generate recommendations for the simulated user\n",
    "    recommendations = generate_recommendations(user_id, user_matrix, pearson_sim, movies, num_recommendations=10)\n",
    "    print(f\"Recommendations for simulated user {user_id}:\")\n",
    "    if recommendations.empty:\n",
    "        print(\"No recommendations available.\")\n",
    "    else:\n",
    "        print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Matrix and Norm Matrix Created.\n",
      "Similarity Matrices Computed.\n",
      "RMSE for Pearson Correlation: 0.7075622590235725\n",
      "RMSE for Cosine Similarity: 0.7075622590235742\n",
      "RMSE for Jaccard Similarity: 1.8958430031549052\n",
      "Recommendations for simulated user 99999:\n",
      "                                                  title  predicted_rating\n",
      "108                                   Braveheart (1995)           6.26285\n",
      "257           Star Wars: Episode IV - A New Hope (1977)           6.26285\n",
      "314                    Shawshank Redemption, The (1994)           6.26285\n",
      "328                                    Tommy Boy (1995)           6.26285\n",
      "452                                Fugitive, The (1993)           6.26285\n",
      "522                             Schindler's List (1993)           6.26285\n",
      "1108             Monty Python and the Holy Grail (1975)           6.26285\n",
      "1166  Star Wars: Episode V - The Empire Strikes Back...           6.26285\n",
      "1167                         Princess Bride, The (1987)           6.26285\n",
      "1179  Star Wars: Episode VI - Return of the Jedi (1983)           6.26285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-chaimaa.abi-29643/ipykernel_2685583/177996546.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recommended_movies['predicted_rating'] = [item[1] for item in recommended_items if item[0] in recommended_movies['movieId'].values]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
